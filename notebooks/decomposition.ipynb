{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "from bayesianquilts.tf.parameter import Interactions, Decomposed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider extending the linear regression problem\n",
    "\n",
    "$$ y = \\vec{x} \\cdot \\vec{\\beta} $$\n",
    "\n",
    "so that $\\beta$ can vary. Let's assume that $\\vec{\\beta}$ is $100$ dimensional\n",
    "\n",
    "Let's say you have some number of **discrete** factors over which you would like to vary $\\beta$, for example, you might have sex, race, and whether one is currently a smoker. Let's assume you have 5 possible values for race, two for sex, and two for smoker status. Then you have $2\\times 5\\times 2=20$ different possible groups over which to fit your model, and $20\\times 100=2000$ total regression parameters.\n",
    "\n",
    "A common approach is to divide the data into these 20 groups, and fit 20 separate models. One can see who this procedure would be statistically problematic  already with this simple example. We would like to define a way of regularizing such a problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter decomposition method\n",
    "\n",
    "In dividing the data into 20 groups, one doesn't allow the groups to share information. Instead, let's consider decomposing the parameter $\\beta$ in terms of the order of interactions, so $\\beta=\\beta_0 + \\beta_{sex}+\\beta_{race}+\\beta_{smoking} + \\beta_{sex, gender} + \\ldots $\n",
    "\n",
    "## WHY??\n",
    "\n",
    "The reason we  want to do this is because we can increase the strength of the regularization for higher order terms, in effect more-strongly forcing more of the higher-order contributions to zero by default. What this procedure does is partially pool the information in the dataset so that the model is effectively lower-order except in places where the data supports high-order contributions.\n",
    "\n",
    "The `Interaction` and `Decomposed` classes work together in creating this decomposition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interaction dimenions: [('sex', 2), ('race', 5), ('smoking', 2)]\n"
     ]
    }
   ],
   "source": [
    "interaction = Interactions(\n",
    "    [\n",
    "        ('sex', 2),\n",
    "        ('race', 5),\n",
    "        ('smoking', 2)\n",
    "    ], exclusions=[]\n",
    "    )\n",
    "\n",
    "print(interaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter shape: [100] \n",
      "Interaction dimenions: [('sex', 2), ('race', 5), ('smoking', 2)] \n",
      "Component tensors: 8 \n",
      "Effective parameter cardinality: 2000 \n",
      "Actual parameter cardinality: 5400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "beta = Decomposed(\n",
    "    param_shape=[100],\n",
    "    interactions=interaction,\n",
    "    name='beta'\n",
    ")\n",
    "print(beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have created a representation for $\\vec{\\beta}$ that consists of eight component parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'beta__': TensorShape([1, 1, 1, 100]), 'beta__smoking': TensorShape([1, 1, 2, 100]), 'beta__race': TensorShape([1, 5, 1, 100]), 'beta__race_smoking': TensorShape([1, 5, 2, 100]), 'beta__sex': TensorShape([2, 1, 1, 100]), 'beta__sex_smoking': TensorShape([2, 1, 2, 100]), 'beta__sex_race': TensorShape([2, 5, 1, 100]), 'beta__sex_race_smoking': TensorShape([2, 5, 2, 100])}\n"
     ]
    }
   ],
   "source": [
    "print(beta._param_shapes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Decomposed` class created the constituent parameters and initialized them to a value which is default of $\\vec{0}$.\n",
    "\n",
    "We can also choose to exclude certain interactions. Let's say we think the model should exclude the interaction between race and sex not qualified by smoking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter shape: [100] \n",
      "Interaction dimenions: [('sex', 2), ('race', 5), ('smoking', 2)] \n",
      "Component tensors: 7 \n",
      "Effective parameter cardinality: 2000 \n",
      "Actual parameter cardinality: 4400\n",
      "\n",
      "{'beta__': TensorShape([1, 1, 1, 100]), 'beta__smoking': TensorShape([1, 1, 2, 100]), 'beta__race': TensorShape([1, 5, 1, 100]), 'beta__race_smoking': TensorShape([1, 5, 2, 100]), 'beta__sex': TensorShape([2, 1, 1, 100]), 'beta__sex_smoking': TensorShape([2, 1, 2, 100]), 'beta__sex_race_smoking': TensorShape([2, 5, 2, 100])}\n"
     ]
    }
   ],
   "source": [
    "interaction = Interactions(\n",
    "    [\n",
    "        ('sex', 2),\n",
    "        ('race', 5),\n",
    "        ('smoking', 2)\n",
    "    ], exclusions=[('race', 'sex')]\n",
    "    )\n",
    "\n",
    "beta = Decomposed(\n",
    "    param_shape=[100],\n",
    "    interactions=interaction,\n",
    "    name='beta'\n",
    ")\n",
    "print(beta)\n",
    "print(beta._param_shapes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You see that the number of constituent tensors is now $7$. In practice, we might wish to exclude higher order terms in order to save memory.\n",
    "\n",
    "Now we have created the decomposition. Let's use the decomposition. Suppose I have a sample of people:\n",
    "\n",
    "1. sex=1, race=1, smoking=1\n",
    "2. sex=0, race=3, smoking=0\n",
    "3. sex=0, race=2, smoking=1\n",
    "4. sex=1, race=0, smoking=1\n",
    "\n",
    " and I want to retrieve the effect values of $\\vec{\\beta}$ for these people. The `Decomposed` class takes care of this lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 100)\n"
     ]
    }
   ],
   "source": [
    "indices = [\n",
    "    [1, 1, 1],\n",
    "    [0, 3, 0],\n",
    "    [0, 2, 1],\n",
    "    [1, 0, 1]\n",
    "]\n",
    "\n",
    "beta_effective = beta.query(indices)\n",
    "print(beta_effective.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You see that I have $4 \\times 100$ values that are returned, where each row corresponds to the regression parameter vector for each of the people."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter batches\n",
    "\n",
    "TFP works on parameters in sample batches. The `Decomposed` class handles batching. Let's generate a batch of size $5$ of the component tensors that add to $\\vec{\\beta}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['beta__: (5, 1, 1, 1, 100)', 'beta__smoking: (5, 1, 1, 2, 100)', 'beta__race: (5, 1, 5, 1, 100)', 'beta__race_smoking: (5, 1, 5, 2, 100)', 'beta__sex: (5, 2, 1, 1, 100)', 'beta__sex_smoking: (5, 2, 1, 2, 100)', 'beta__sex_race_smoking: (5, 2, 5, 2, 100)']\n"
     ]
    }
   ],
   "source": [
    "t, l = beta.generate_tensors(batch_shape=[5])\n",
    "print([f\"{k}: {v.shape}\" for k, v in t.items()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now let's query the batched parameter to get batched effective values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 4, 100)\n"
     ]
    }
   ],
   "source": [
    "beta.set_params(t)\n",
    "effective_batched = beta.query(indices)\n",
    "print(effective_batched.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So you see that for each of the 4 people we have a batch of size 5, of the vector $\\vec{\\beta}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inflating and deflating the indices\n",
    "\n",
    "Tensorflow has an intrinisic limitation in the tensor rank allowed in its most basic operations. To get around this limitation, we can inflate and deflate the interaction index dimensions. Let's take a look at generating deflated constituent parameters and inflating them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['beta__: (5, 1, 100)', 'beta__smoking: (5, 2, 100)', 'beta__race: (5, 5, 100)', 'beta__race_smoking: (5, 10, 100)', 'beta__sex: (5, 2, 100)', 'beta__sex_smoking: (5, 4, 100)', 'beta__sex_race_smoking: (5, 20, 100)']\n"
     ]
    }
   ],
   "source": [
    "t, n = beta.generate_tensors(batch_shape=[5], flatten_indices=True)\n",
    "print([f\"{k}: {v.shape}\" for k, v in t.items()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So you see here that the middle axes corresponding to the interaction indices has collapsed into a single axis in each of the parameter tensors. To re-inflate, we have the method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['beta__: (5, 1, 1, 1, 100)', 'beta__smoking: (5, 1, 1, 2, 100)', 'beta__race: (5, 1, 5, 1, 100)', 'beta__race_smoking: (5, 1, 5, 2, 100)', 'beta__sex: (5, 2, 1, 1, 100)', 'beta__sex_smoking: (5, 2, 1, 2, 100)', 'beta__sex_race_smoking: (5, 2, 5, 2, 100)']\n"
     ]
    }
   ],
   "source": [
    "t1 = beta.inflate_indices(t)\n",
    "print([f\"{k}: {v.shape}\" for k, v in t1.items()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And all is good in the world. Happy 2022!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
