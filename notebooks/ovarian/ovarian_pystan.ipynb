{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ovarian dataset Logistic Regression using MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "from itertools import chain\n",
    "\n",
    "from cmdstanpy import CmdStanModel\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "from random import choices\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import tensorflow_probability.python.bijectors as tfb\n",
    "\n",
    "from bayesianquilts.models.logistic_regression_reparam import LogisticRegression2\n",
    "from bayesianquilts.metrics.classification import classification_metrics\n",
    "# from bayesianquilts.sampler import psis, nppsis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54, 1536)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_ = pd.read_csv(Path.home() / \"workspace\" / \"bayesianquilts\"/ \"bayesianquilts\"/ \"data\" / \"overianx.csv\", header=None)\n",
    "y_ = pd.read_table(Path.home() / \"workspace\" / \"bayesianquilts\"/ \"bayesianquilts\"/ \"data\" / \"overiany.csv\", header=None)\n",
    "\n",
    "\n",
    "X_scaled = (X_ - X_.mean())/X_.std()\n",
    "X_scaled = X_scaled.fillna(0).to_numpy()\n",
    "y_ = y_.to_numpy()\n",
    "N = X_scaled.shape[0]\n",
    "d = X_scaled.shape[1]\n",
    "\n",
    "print((N, d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_horseshoe_code = \"\"\"\n",
    "data {\n",
    "  int <lower=0> N;                // number  of  observations\n",
    "  int <lower=0> d;                // number  of  predictors\n",
    "  array[N] int<lower=0,upper=1> y;      // outputs\n",
    "  matrix[N,d] x;                  // inputs\n",
    "  real <lower=0>  scale_icept;    // prior  std for  the  intercept\n",
    "  real <lower=0>  scale_global;   // scale  for  the half -t prior  for  tau\n",
    "  real <lower=1>  nu_global;      // degrees  of  freedom  for the half -t prior for tau\n",
    "  real <lower=1> nu_local;        // degrees  of  freedom  for  the half -t priors for  lambdas\n",
    "  real <lower=0>  slab_scale;     // slab  scale  for  the  regularized  horseshoe\n",
    "  real <lower=0> slab_df;         // slab  degrees  of  freedom  for the  regularized horseshoe\n",
    "\n",
    "  //int<lower=0> N_tilde;\n",
    "  //matrix[N_tilde, d] x_tilde;\n",
    "  //array[N_tilde] int<lower=0,upper=1> y_obs;\n",
    "}\n",
    "parameters {\n",
    "  real  beta0;\n",
    "  vector[d] z;\n",
    "  real <lower=0> tau;             // global  shrinkage  parameter\n",
    "  vector <lower =0>[d] lambda;    // local  shrinkage  parameter\n",
    "  real <lower=0> caux;\n",
    "}\n",
    "transformed  parameters {\n",
    "  vector <lower =0>[d] lambda_tilde;    // ’truncated ’ local  shrinkage  parameter\n",
    "  real <lower=0> c;                     // slab  scale\n",
    "  vector[d] beta;                       // regression  coefficients\n",
    "  vector[N] f;                          // latent  function  values\n",
    "  c = slab_scale * sqrt(caux);\n",
    "  lambda_tilde = sqrt( c^2 * square(lambda) ./ (c^2 + tau^2* square(lambda )) );\n",
    "  beta = z .*  lambda_tilde*tau;\n",
    "  f = beta0 + x*beta;\n",
    "}\n",
    "model {\n",
    "  z ~ normal(0.0, 1.0); // half -t priors  for  lambdas  and tau , and  inverse -gamma  for c^2\n",
    "  lambda ~ student_t(nu_local , 0.0, 1.0);\n",
    "  tau ~ student_t(nu_global , 0.0, scale_global);\n",
    "  caux ~ inv_gamma (0.5* slab_df , 0.5* slab_df );\n",
    "  beta0 ~ normal(0.0,  scale_icept );\n",
    "  y ~ bernoulli_logit(f);\n",
    "}\n",
    "generated quantities {\n",
    "  vector[N] log_lik;\n",
    "  // vector[N_tilde] loo_log_lik;\n",
    "\n",
    "  for (nn in 1:N)\n",
    "    log_lik[nn] = bernoulli_logit_lpmf(y[nn] | x[nn] * beta + beta0);\n",
    "\n",
    "  //for (nn in 1:N_tilde)\n",
    "  //  loo_log_lik[nn] = bernoulli_logit_lpmf(y_obs[nn] | x_tilde[nn] * beta + beta0);\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "with open(\"ovarian_model.stan\", 'w') as f:\n",
    "  f.writelines(logistic_horseshoe_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01:10:22 - cmdstanpy - INFO - compiling stan file /Users/changjc/workspace/bayesianquilts/ovarian_model.stan to exe file /Users/changjc/workspace/bayesianquilts/ovarian_model\n",
      "01:10:32 - cmdstanpy - INFO - compiled model executable: /Users/changjc/workspace/bayesianquilts/ovarian_model\n"
     ]
    }
   ],
   "source": [
    "sm = CmdStanModel(stan_file=\"ovarian_model.stan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "guessnumrelevcov = 20 # 20.\n",
    "slab_scale = 2.5/100\n",
    "scale_icept = 5.0\n",
    "nu_global = 1\n",
    "nu_local = 1\n",
    "slab_df = 1\n",
    "scale_global = guessnumrelevcov / ((d - guessnumrelevcov) * np.sqrt(N))/10000\n",
    "\n",
    "control = {\"adapt_delta\": 0.9995, \"max_treedepth\": 15}\n",
    "\n",
    "ovarian_data = {\n",
    "    \"N\": N,\n",
    "    \"d\": d,\n",
    "    \"slab_df\": slab_df,\n",
    "    \"slab_scale\": slab_scale,\n",
    "    \"scale_icept\": scale_icept,\n",
    "    \"nu_global\": 1,\n",
    "    \"nu_local\": 1,\n",
    "    \"scale_global\": scale_global,\n",
    "    \"y\": y_.astype(int)[:, 0].tolist(),\n",
    "    \"x\": X_scaled.tolist(),\n",
    "}\n",
    "\n",
    "import json\n",
    "with open(\"ovarian_data.json\", 'w') as f:\n",
    "    json.dump(ovarian_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01:10:32 - cmdstanpy - INFO - CmdStan start processing\n",
      "chain 1 |\u001b[33m          \u001b[0m| 00:00 Status\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1 |\u001b[33m          \u001b[0m| 00:03 Iteration:     1 / 22000 [  0%]  (Warmup)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "chain 1 |\u001b[33m▏         \u001b[0m| 00:15 Iteration:   100 / 22000 [  0%]  (Warmup)\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1 |\u001b[33m▏         \u001b[0m| 00:27 Iteration:   200 / 22000 [  0%]  (Warmup)\n",
      "\n",
      "chain 1 |\u001b[33m▏         \u001b[0m| 00:32 Iteration:   300 / 22000 [  1%]  (Warmup)\n",
      "chain 1 |\u001b[33m▎         \u001b[0m| 00:44 Iteration:   400 / 22000 [  1%]  (Warmup)\n",
      "\n",
      "chain 1 |\u001b[33m▎         \u001b[0m| 00:47 Iteration:   500 / 22000 [  2%]  (Warmup)\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1 |\u001b[33m▎         \u001b[0m| 00:56 Iteration:   600 / 22000 [  2%]  (Warmup)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1 |\u001b[33m▍         \u001b[0m| 01:02 Iteration:   700 / 22000 [  3%]  (Warmup)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1 |\u001b[33m▍         \u001b[0m| 01:12 Iteration:   800 / 22000 [  3%]  (Warmup)\n",
      "chain 1 |\u001b[33m▌         \u001b[0m| 01:22 Iteration:  1000 / 22000 [  4%]  (Warmup)\n",
      "chain 1 |\u001b[33m▌         \u001b[0m| 01:28 Iteration:  1100 / 22000 [  5%]  (Warmup)\n",
      "\u001b[A\n",
      "\n",
      "chain 1 |\u001b[33m▋         \u001b[0m| 01:34 Iteration:  1200 / 22000 [  5%]  (Warmup)\n",
      "\u001b[A\n",
      "\n",
      "chain 1 |\u001b[33m▋         \u001b[0m| 01:46 Iteration:  1400 / 22000 [  6%]  (Warmup)\n",
      "\u001b[A\n",
      "\n",
      "chain 1 |\u001b[33m▊         \u001b[0m| 01:52 Iteration:  1500 / 22000 [  6%]  (Warmup)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1 |\u001b[33m▊         \u001b[0m| 02:01 Iteration:  1600 / 22000 [  7%]  (Warmup)\n",
      "\n",
      "chain 1 |\u001b[33m▊         \u001b[0m| 02:07 Iteration:  1700 / 22000 [  7%]  (Warmup)\n",
      "chain 1 |\u001b[33m▉         \u001b[0m| 02:12 Iteration:  1800 / 22000 [  8%]  (Warmup)\n",
      "\n",
      "chain 1 |\u001b[33m▉         \u001b[0m| 02:17 Iteration:  1900 / 22000 [  8%]  (Warmup)\n",
      "chain 1 |\u001b[33m▉         \u001b[0m| 02:23 Iteration:  2000 / 22000 [  9%]  (Warmup)\n",
      "\u001b[A\n",
      "\n",
      "chain 1 |\u001b[33m█         \u001b[0m| 02:28 Iteration:  2100 / 22000 [  9%]  (Warmup)\n",
      "chain 1 |\u001b[33m█         \u001b[0m| 02:34 Iteration:  2200 / 22000 [ 10%]  (Warmup)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1 |\u001b[33m█▏        \u001b[0m| 02:43 Iteration:  2300 / 22000 [ 10%]  (Warmup)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1 |\u001b[33m█▏        \u001b[0m| 02:50 Iteration:  2400 / 22000 [ 10%]  (Warmup)\n",
      "\n",
      "chain 1 |\u001b[33m█▏        \u001b[0m| 02:58 Iteration:  2500 / 22000 [ 11%]  (Warmup)\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "chain 1 |\u001b[33m█▎        \u001b[0m| 03:08 Iteration:  2600 / 22000 [ 11%]  (Warmup)\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1 |\u001b[33m█▎        \u001b[0m| 03:17 Iteration:  2700 / 22000 [ 12%]  (Warmup)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1 |\u001b[33m█▎        \u001b[0m| 03:25 Iteration:  2800 / 22000 [ 12%]  (Warmup)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1 |\u001b[33m█▍        \u001b[0m| 03:36 Iteration:  2900 / 22000 [ 13%]  (Warmup)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "chain 1 |\u001b[33m█▍        \u001b[0m| 03:46 Iteration:  3000 / 22000 [ 13%]  (Warmup)\n",
      "\u001b[A\n",
      "\n",
      "chain 1 |\u001b[33m█▍        \u001b[0m| 03:57 Iteration:  3100 / 22000 [ 14%]  (Warmup)\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1 |\u001b[33m█▌        \u001b[0m| 04:14 Iteration:  3300 / 22000 [ 15%]  (Warmup)\n",
      "\n",
      "chain 1 |\u001b[33m█▌        \u001b[0m| 04:19 Iteration:  3400 / 22000 [ 15%]  (Warmup)\n",
      "chain 1 |\u001b[33m█▋        \u001b[0m| 04:25 Iteration:  3500 / 22000 [ 15%]  (Warmup)\n",
      "\n",
      "chain 1 |\u001b[33m█▊        \u001b[0m| 04:36 Iteration:  3700 / 22000 [ 16%]  (Warmup)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1 |\u001b[33m█▊        \u001b[0m| 04:41 Iteration:  3800 / 22000 [ 17%]  (Warmup)\n",
      "\u001b[A\n",
      "\n",
      "chain 1 |\u001b[33m█▉        \u001b[0m| 04:52 Iteration:  4000 / 22000 [ 18%]  (Warmup)\n",
      "chain 1 |\u001b[33m█▉        \u001b[0m| 04:58 Iteration:  4100 / 22000 [ 18%]  (Warmup)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1 |\u001b[33m█▉        \u001b[0m| 05:03 Iteration:  4200 / 22000 [ 19%]  (Warmup)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1 |\u001b[33m██        \u001b[0m| 05:11 Iteration:  4300 / 22000 [ 19%]  (Warmup)\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1 |\u001b[33m██        \u001b[0m| 05:21 Iteration:  4400 / 22000 [ 20%]  (Warmup)\n",
      "\u001b[A\n",
      "\n",
      "chain 1 |\u001b[33m██        \u001b[0m| 05:32 Iteration:  4500 / 22000 [ 20%]  (Warmup)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "chain 1 |\u001b[33m██▏       \u001b[0m| 05:42 Iteration:  4600 / 22000 [ 20%]  (Warmup)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "chain 1 |\u001b[33m██▏       \u001b[0m| 05:53 Iteration:  4700 / 22000 [ 21%]  (Warmup)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "chain 1 |\u001b[33m██▎       \u001b[0m| 06:04 Iteration:  4800 / 22000 [ 21%]  (Warmup)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1 |\u001b[33m██▎       \u001b[0m| 06:12 Iteration:  4900 / 22000 [ 22%]  (Warmup)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "chain 1 |\u001b[33m██▎       \u001b[0m| 06:23 Iteration:  5000 / 22000 [ 22%]  (Warmup)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1 |\u001b[33m██▍       \u001b[0m| 06:32 Iteration:  5100 / 22000 [ 23%]  (Warmup)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1 |\u001b[33m██▍       \u001b[0m| 06:43 Iteration:  5200 / 22000 [ 23%]  (Warmup)\n",
      "\n",
      "chain 1 |\u001b[33m██▍       \u001b[0m| 06:53 Iteration:  5300 / 22000 [ 24%]  (Warmup)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1 |\u001b[33m██▌       \u001b[0m| 07:03 Iteration:  5400 / 22000 [ 24%]  (Warmup)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1 |\u001b[33m██▌       \u001b[0m| 07:14 Iteration:  5500 / 22000 [ 25%]  (Warmup)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1 |\u001b[33m██▌       \u001b[0m| 07:24 Iteration:  5600 / 22000 [ 25%]  (Warmup)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1 |\u001b[33m██▋       \u001b[0m| 07:35 Iteration:  5700 / 22000 [ 25%]  (Warmup)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1 |\u001b[33m██▋       \u001b[0m| 07:45 Iteration:  5800 / 22000 [ 26%]  (Warmup)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1 |\u001b[33m██▋       \u001b[0m| 07:55 Iteration:  5900 / 22000 [ 26%]  (Warmup)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1 |\u001b[33m██▊       \u001b[0m| 08:06 Iteration:  6000 / 22000 [ 27%]  (Warmup)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1 |\u001b[33m██▊       \u001b[0m| 08:16 Iteration:  6100 / 22000 [ 27%]  (Warmup)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1 |\u001b[33m██▉       \u001b[0m| 08:27 Iteration:  6200 / 22000 [ 28%]  (Warmup)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1 |\u001b[33m██▉       \u001b[0m| 08:37 Iteration:  6300 / 22000 [ 28%]  (Warmup)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "chain 1 |\u001b[33m██▉       \u001b[0m| 08:54 Iteration:  6400 / 22000 [ 29%]  (Warmup)\n",
      "chain 1 |\u001b[33m███       \u001b[0m| 09:01 Iteration:  6500 / 22000 [ 29%]  (Warmup)\n",
      "\n",
      "chain 1 |\u001b[33m███       \u001b[0m| 09:06 Iteration:  6600 / 22000 [ 30%]  (Warmup)\n",
      "chain 1 |\u001b[33m███       \u001b[0m| 09:11 Iteration:  6700 / 22000 [ 30%]  (Warmup)\n",
      "\n",
      "chain 1 |\u001b[33m███▏      \u001b[0m| 09:16 Iteration:  6800 / 22000 [ 30%]  (Warmup)\n",
      "chain 1 |\u001b[33m███▏      \u001b[0m| 09:22 Iteration:  6900 / 22000 [ 31%]  (Warmup)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1 |\u001b[33m███▏      \u001b[0m| 09:31 Iteration:  7000 / 22000 [ 31%]  (Warmup)\n",
      "\n",
      "chain 1 |\u001b[33m███▎      \u001b[0m| 09:38 Iteration:  7100 / 22000 [ 32%]  (Warmup)\n",
      "\u001b[A\n",
      "\n",
      "chain 1 |\u001b[33m███▎      \u001b[0m| 09:45 Iteration:  7200 / 22000 [ 32%]  (Warmup)\n",
      "\u001b[A\n",
      "\n",
      "chain 1 |\u001b[33m███▍      \u001b[0m| 09:53 Iteration:  7300 / 22000 [ 33%]  (Warmup)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1 |\u001b[33m███▍      \u001b[0m| 10:03 Iteration:  7400 / 22000 [ 33%]  (Warmup)\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1 |\u001b[33m███▍      \u001b[0m| 10:13 Iteration:  7500 / 22000 [ 34%]  (Warmup)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "chain 1 |\u001b[33m███▌      \u001b[0m| 10:24 Iteration:  7600 / 22000 [ 34%]  (Warmup)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1 |\u001b[33m███▌      \u001b[0m| 10:34 Iteration:  7700 / 22000 [ 35%]  (Warmup)\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1 |\u001b[33m███▌      \u001b[0m| 10:45 Iteration:  7800 / 22000 [ 35%]  (Warmup)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "chain 1 |\u001b[33m███▋      \u001b[0m| 10:55 Iteration:  7900 / 22000 [ 35%]  (Warmup)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1 |\u001b[33m███▋      \u001b[0m| 11:05 Iteration:  8000 / 22000 [ 36%]  (Warmup)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1 |\u001b[33m███▋      \u001b[0m| 11:16 Iteration:  8100 / 22000 [ 36%]  (Warmup)\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1 |\u001b[33m███▊      \u001b[0m| 11:26 Iteration:  8200 / 22000 [ 37%]  (Warmup)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1 |\u001b[33m███▊      \u001b[0m| 11:37 Iteration:  8300 / 22000 [ 37%]  (Warmup)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1 |\u001b[33m███▊      \u001b[0m| 11:47 Iteration:  8400 / 22000 [ 38%]  (Warmup)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1 |\u001b[33m███▉      \u001b[0m| 11:58 Iteration:  8500 / 22000 [ 38%]  (Warmup)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1 |\u001b[33m███▉      \u001b[0m| 12:08 Iteration:  8600 / 22000 [ 39%]  (Warmup)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1 |\u001b[33m████      \u001b[0m| 12:19 Iteration:  8700 / 22000 [ 39%]  (Warmup)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1 |\u001b[33m████      \u001b[0m| 12:29 Iteration:  8800 / 22000 [ 40%]  (Warmup)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1 |\u001b[33m████      \u001b[0m| 12:39 Iteration:  8900 / 22000 [ 40%]  (Warmup)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1 |\u001b[33m████▏     \u001b[0m| 12:50 Iteration:  9000 / 22000 [ 40%]  (Warmup)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1 |\u001b[33m████▏     \u001b[0m| 13:00 Iteration:  9100 / 22000 [ 41%]  (Warmup)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1 |\u001b[33m████▏     \u001b[0m| 13:10 Iteration:  9200 / 22000 [ 41%]  (Warmup)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1 |\u001b[33m████▎     \u001b[0m| 13:20 Iteration:  9300 / 22000 [ 42%]  (Warmup)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1 |\u001b[33m████▎     \u001b[0m| 13:31 Iteration:  9400 / 22000 [ 42%]  (Warmup)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1 |\u001b[33m████▎     \u001b[0m| 13:41 Iteration:  9500 / 22000 [ 43%]  (Warmup)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1 |\u001b[33m████▍     \u001b[0m| 13:51 Iteration:  9600 / 22000 [ 43%]  (Warmup)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1 |\u001b[33m████▍     \u001b[0m| 14:02 Iteration:  9700 / 22000 [ 44%]  (Warmup)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1 |\u001b[33m████▌     \u001b[0m| 14:12 Iteration:  9800 / 22000 [ 44%]  (Warmup)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1 |\u001b[33m████▌     \u001b[0m| 14:22 Iteration:  9900 / 22000 [ 45%]  (Warmup)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1 |\u001b[33m████▌     \u001b[0m| 14:33 Iteration: 10000 / 22000 [ 45%]  (Warmup)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1 |\u001b[33m████▋     \u001b[0m| 14:44 Iteration: 10100 / 22000 [ 45%]  (Warmup)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1 |\u001b[33m████▋     \u001b[0m| 14:54 Iteration: 10200 / 22000 [ 46%]  (Warmup)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1 |\u001b[33m████▋     \u001b[0m| 15:04 Iteration: 10300 / 22000 [ 46%]  (Warmup)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1 |\u001b[33m████▊     \u001b[0m| 15:15 Iteration: 10400 / 22000 [ 47%]  (Warmup)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "chain 1 |\u001b[33m████▊     \u001b[0m| 15:25 Iteration: 10500 / 22000 [ 47%]  (Warmup)\n",
      "\n",
      "chain 1 |\u001b[33m████▊     \u001b[0m| 15:36 Iteration: 10600 / 22000 [ 48%]  (Warmup)\n",
      "\u001b[A\n",
      "\n",
      "chain 1 |\u001b[33m████▉     \u001b[0m| 15:46 Iteration: 10700 / 22000 [ 48%]  (Warmup)\n",
      "\u001b[A\n",
      "\n",
      "chain 1 |\u001b[33m████▉     \u001b[0m| 15:57 Iteration: 10800 / 22000 [ 49%]  (Warmup)\n",
      "\u001b[A\n",
      "\n",
      "chain 1 |\u001b[33m█████     \u001b[0m| 16:07 Iteration: 10900 / 22000 [ 49%]  (Warmup)\n",
      "\u001b[A\n",
      "\n",
      "chain 1 |\u001b[33m█████     \u001b[0m| 16:17 Iteration: 11000 / 22000 [ 50%]  (Warmup)\n",
      "\u001b[A\n",
      "\n",
      "chain 1 |\u001b[33m█████     \u001b[0m| 16:28 Iteration: 11100 / 22000 [ 50%]  (Warmup)\n",
      "\u001b[A\n",
      "\n",
      "chain 1 |\u001b[33m█████▏    \u001b[0m| 16:38 Iteration: 11200 / 22000 [ 50%]  (Warmup)\n",
      "\u001b[A\n",
      "\n",
      "chain 1 |\u001b[33m█████▏    \u001b[0m| 16:48 Iteration: 11300 / 22000 [ 51%]  (Warmup)\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A"
     ]
    }
   ],
   "source": [
    "fit = sm.sample(\n",
    "    data=\"ovarian_data.json\",\n",
    "    iter_warmup=20000,\n",
    "    iter_sampling=2000,\n",
    "    thin=2,\n",
    "    adapt_delta=0.9995,\n",
    "    max_treedepth=15,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CmdStanMCMC: model=ovarian_model chains=4['method=sample', 'num_samples=2000', 'num_warmup=20000', 'thin=2', 'algorithm=hmc', 'engine=nuts', 'max_depth=15', 'adapt', 'engaged=1', 'delta=0.9995']\n",
      " csv_files:\n",
      "\t/var/folders/6s/m6kbjxb16sl9cg9rg6mj5czrv6ht9f/T/tmpn_15wk27/ovarian_modelg6w_h2cs/ovarian_model-20240403143919_1.csv\n",
      "\t/var/folders/6s/m6kbjxb16sl9cg9rg6mj5czrv6ht9f/T/tmpn_15wk27/ovarian_modelg6w_h2cs/ovarian_model-20240403143919_2.csv\n",
      "\t/var/folders/6s/m6kbjxb16sl9cg9rg6mj5czrv6ht9f/T/tmpn_15wk27/ovarian_modelg6w_h2cs/ovarian_model-20240403143919_3.csv\n",
      "\t/var/folders/6s/m6kbjxb16sl9cg9rg6mj5czrv6ht9f/T/tmpn_15wk27/ovarian_modelg6w_h2cs/ovarian_model-20240403143919_4.csv\n",
      " output_files:\n",
      "\t/var/folders/6s/m6kbjxb16sl9cg9rg6mj5czrv6ht9f/T/tmpn_15wk27/ovarian_modelg6w_h2cs/ovarian_model-20240403143919_0-stdout.txt\n",
      "\t/var/folders/6s/m6kbjxb16sl9cg9rg6mj5czrv6ht9f/T/tmpn_15wk27/ovarian_modelg6w_h2cs/ovarian_model-20240403143919_1-stdout.txt\n",
      "\t/var/folders/6s/m6kbjxb16sl9cg9rg6mj5czrv6ht9f/T/tmpn_15wk27/ovarian_modelg6w_h2cs/ovarian_model-20240403143919_2-stdout.txt\n",
      "\t/var/folders/6s/m6kbjxb16sl9cg9rg6mj5czrv6ht9f/T/tmpn_15wk27/ovarian_modelg6w_h2cs/ovarian_model-20240403143919_3-stdout.txt\n"
     ]
    }
   ],
   "source": [
    "print(fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing csv files: /var/folders/6s/m6kbjxb16sl9cg9rg6mj5czrv6ht9f/T/tmpn_15wk27/ovarian_modelg6w_h2cs/ovarian_model-20240403143919_1.csv, /var/folders/6s/m6kbjxb16sl9cg9rg6mj5czrv6ht9f/T/tmpn_15wk27/ovarian_modelg6w_h2cs/ovarian_model-20240403143919_2.csv, /var/folders/6s/m6kbjxb16sl9cg9rg6mj5czrv6ht9f/T/tmpn_15wk27/ovarian_modelg6w_h2cs/ovarian_model-20240403143919_3.csv, /var/folders/6s/m6kbjxb16sl9cg9rg6mj5czrv6ht9f/T/tmpn_15wk27/ovarian_modelg6w_h2cs/ovarian_model-20240403143919_4.csv\n",
      "\n",
      "Checking sampler transitions treedepth.\n",
      "Treedepth satisfactory for all transitions.\n",
      "\n",
      "Checking sampler transitions for divergences.\n",
      "No divergent transitions found.\n",
      "\n",
      "Checking E-BFMI - sampler transitions HMC potential energy.\n",
      "E-BFMI satisfactory.\n",
      "\n",
      "Effective sample size satisfactory.\n",
      "\n",
      "The following parameters had split R-hat greater than 1.05:\n",
      "  z[1491], beta[1483], beta[1491], log_lik[6], log_lik[24], log_lik[36]\n",
      "Such high values indicate incomplete mixing and biased estimation.\n",
      "You should consider regularizating your model with additional prior information or a more effective parameterization.\n",
      "\n",
      "Processing complete.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(fit.diagnose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>MCSE</th>\n",
       "      <th>StdDev</th>\n",
       "      <th>5%</th>\n",
       "      <th>50%</th>\n",
       "      <th>95%</th>\n",
       "      <th>N_Eff</th>\n",
       "      <th>N_Eff/s</th>\n",
       "      <th>R_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lp__</th>\n",
       "      <td>-2944.360000</td>\n",
       "      <td>0.891933</td>\n",
       "      <td>44.848600</td>\n",
       "      <td>-3017.660000</td>\n",
       "      <td>-2943.840000</td>\n",
       "      <td>-2.871370e+03</td>\n",
       "      <td>2528.330</td>\n",
       "      <td>3.200170</td>\n",
       "      <td>0.999570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta0</th>\n",
       "      <td>1.897480</td>\n",
       "      <td>0.041331</td>\n",
       "      <td>1.536620</td>\n",
       "      <td>0.211224</td>\n",
       "      <td>1.553170</td>\n",
       "      <td>4.918340e+00</td>\n",
       "      <td>1382.240</td>\n",
       "      <td>1.749540</td>\n",
       "      <td>1.003990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>z[1]</th>\n",
       "      <td>-0.002240</td>\n",
       "      <td>0.018340</td>\n",
       "      <td>0.994213</td>\n",
       "      <td>-1.664430</td>\n",
       "      <td>0.023410</td>\n",
       "      <td>1.647160e+00</td>\n",
       "      <td>2938.710</td>\n",
       "      <td>3.719610</td>\n",
       "      <td>1.000440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>z[2]</th>\n",
       "      <td>0.029255</td>\n",
       "      <td>0.017222</td>\n",
       "      <td>0.988722</td>\n",
       "      <td>-1.562150</td>\n",
       "      <td>0.013512</td>\n",
       "      <td>1.668730e+00</td>\n",
       "      <td>3296.000</td>\n",
       "      <td>4.171840</td>\n",
       "      <td>1.000590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>z[3]</th>\n",
       "      <td>0.027492</td>\n",
       "      <td>0.018476</td>\n",
       "      <td>1.005450</td>\n",
       "      <td>-1.611880</td>\n",
       "      <td>0.025639</td>\n",
       "      <td>1.685690e+00</td>\n",
       "      <td>2961.450</td>\n",
       "      <td>3.748390</td>\n",
       "      <td>0.999808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_lik[50]</th>\n",
       "      <td>-0.011049</td>\n",
       "      <td>0.000948</td>\n",
       "      <td>0.043544</td>\n",
       "      <td>-0.048252</td>\n",
       "      <td>-0.001078</td>\n",
       "      <td>-6.316170e-10</td>\n",
       "      <td>2108.790</td>\n",
       "      <td>2.669150</td>\n",
       "      <td>1.003630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_lik[51]</th>\n",
       "      <td>-0.007900</td>\n",
       "      <td>0.000554</td>\n",
       "      <td>0.032888</td>\n",
       "      <td>-0.036041</td>\n",
       "      <td>-0.000606</td>\n",
       "      <td>-1.213240e-10</td>\n",
       "      <td>3521.240</td>\n",
       "      <td>4.456930</td>\n",
       "      <td>1.000770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_lik[52]</th>\n",
       "      <td>-0.017166</td>\n",
       "      <td>0.002217</td>\n",
       "      <td>0.118038</td>\n",
       "      <td>-0.042076</td>\n",
       "      <td>-0.000550</td>\n",
       "      <td>-2.087550e-09</td>\n",
       "      <td>2833.970</td>\n",
       "      <td>3.587030</td>\n",
       "      <td>1.001800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_lik[53]</th>\n",
       "      <td>-1.244270</td>\n",
       "      <td>0.074662</td>\n",
       "      <td>1.060330</td>\n",
       "      <td>-3.102140</td>\n",
       "      <td>-1.145980</td>\n",
       "      <td>-9.905620e-05</td>\n",
       "      <td>201.686</td>\n",
       "      <td>0.255279</td>\n",
       "      <td>1.032670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_lik[54]</th>\n",
       "      <td>-0.014031</td>\n",
       "      <td>0.000660</td>\n",
       "      <td>0.036297</td>\n",
       "      <td>-0.063175</td>\n",
       "      <td>-0.001680</td>\n",
       "      <td>-1.943750e-11</td>\n",
       "      <td>3023.480</td>\n",
       "      <td>3.826910</td>\n",
       "      <td>1.003080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6257 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Mean      MCSE     StdDev           5%          50%  \\\n",
       "lp__        -2944.360000  0.891933  44.848600 -3017.660000 -2943.840000   \n",
       "beta0           1.897480  0.041331   1.536620     0.211224     1.553170   \n",
       "z[1]           -0.002240  0.018340   0.994213    -1.664430     0.023410   \n",
       "z[2]            0.029255  0.017222   0.988722    -1.562150     0.013512   \n",
       "z[3]            0.027492  0.018476   1.005450    -1.611880     0.025639   \n",
       "...                  ...       ...        ...          ...          ...   \n",
       "log_lik[50]    -0.011049  0.000948   0.043544    -0.048252    -0.001078   \n",
       "log_lik[51]    -0.007900  0.000554   0.032888    -0.036041    -0.000606   \n",
       "log_lik[52]    -0.017166  0.002217   0.118038    -0.042076    -0.000550   \n",
       "log_lik[53]    -1.244270  0.074662   1.060330    -3.102140    -1.145980   \n",
       "log_lik[54]    -0.014031  0.000660   0.036297    -0.063175    -0.001680   \n",
       "\n",
       "                      95%     N_Eff   N_Eff/s     R_hat  \n",
       "lp__        -2.871370e+03  2528.330  3.200170  0.999570  \n",
       "beta0        4.918340e+00  1382.240  1.749540  1.003990  \n",
       "z[1]         1.647160e+00  2938.710  3.719610  1.000440  \n",
       "z[2]         1.668730e+00  3296.000  4.171840  1.000590  \n",
       "z[3]         1.685690e+00  2961.450  3.748390  0.999808  \n",
       "...                   ...       ...       ...       ...  \n",
       "log_lik[50] -6.316170e-10  2108.790  2.669150  1.003630  \n",
       "log_lik[51] -1.213240e-10  3521.240  4.456930  1.000770  \n",
       "log_lik[52] -2.087550e-09  2833.970  3.587030  1.001800  \n",
       "log_lik[53] -9.905620e-05   201.686  0.255279  1.032670  \n",
       "log_lik[54] -1.943750e-11  3023.480  3.826910  1.003080  \n",
       "\n",
       "[6257 rows x 9 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit.stan_variable('beta0').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4000, 1536), (54, 1536))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit.stan_variable('beta').shape, X_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7f41c434ba60>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 100x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "beta = tf.reduce_mean(fit.stan_variable(\"beta\"), axis=1, keepdims=True)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(1, 7))\n",
    "im = ax.pcolormesh(beta, cmap='seismic_r')\n",
    "plt.colorbar(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = fit.stan_variables()\n",
    "params.keys()\n",
    "params['c'] = params['c'][:, tf.newaxis]\n",
    "params['tau'] = params['tau'][:, tf.newaxis]\n",
    "params['caux'] = params['caux'][:, tf.newaxis]\n",
    "params['beta0'] = params['beta0'][:, tf.newaxis]\n",
    "\n",
    "n_samples = 128\n",
    "params = {k: v[:n_samples] for k, v in params.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = LogisticRegression2(\n",
    "    dim_regressors=d,\n",
    "    slab_df=slab_df,\n",
    "    slab_scale=slab_scale,\n",
    "    scale_icept=scale_icept,\n",
    "    nu_global=1,\n",
    "    nu_local=1,\n",
    "    scale_global=scale_global,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 1536)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit.stan_variable(\"beta\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "tfdata = tf.data.Dataset.from_tensor_slices({'X': X_scaled, 'y':y_})\n",
    "batch_size = 56\n",
    "def data_factory_factory(batch_size=batch_size, repeat=False, shuffle=False):\n",
    "    def data_factory(batch_size=batch_size):\n",
    "        if shuffle:\n",
    "            out = tfdata.shuffle(batch_size*10)\n",
    "        else:\n",
    "            out = tfdata\n",
    "        \n",
    "        if repeat:\n",
    "            out = out.repeat()\n",
    "        return out.batch(batch_size)\n",
    "    return data_factory\n",
    "\n",
    "batch = next(iter(data_factory_factory()()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 36.64it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def prediction_fn(data):\n",
    "    pred = lr_model.predictive_distribution(data, **params)[\"logits\"]\n",
    "    return tf.reduce_mean(pred, axis=0)\n",
    "\n",
    "bench = classification_metrics(\n",
    "    data_factory=data_factory_factory(),\n",
    "    prediction_fn=prediction_fn,\n",
    "    outcome_label='y',\n",
    "    by_vars=[]\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(9, 2))\n",
    "ax[0].plot(bench['auroc']['fpr'], bench['auroc']['tpr'])\n",
    "ax[0].text(0.5, 0.1, f\"AUROC: {round(bench['auroc']['auroc'], 2)}\")\n",
    "ax[0].set_xlim((0, 1))\n",
    "ax[0].set_ylim((0, 1))\n",
    "ax[0].set_title(\"ROC\")\n",
    "\n",
    "ax[1].plot(bench['auprc']['recall'], bench['auprc']['precision'])\n",
    "ax[1].text(0.5, 0.8, f\"AUPRC: {round(bench['auprc']['auprc'], 2)}\")\n",
    "ax[1].set_title(\"Precision-Recall\")\n",
    "ax[1].set_xlim((0, 1))\n",
    "ax[1].set_ylim((0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-10 04:11:53.635192: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 4586471424 exceeds 10% of free system memory.\n",
      "2024-02-10 04:11:54.529041: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 4586471424 exceeds 10% of free system memory.\n",
      "2024-02-10 04:11:55.396526: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 4586471424 exceeds 10% of free system memory.\n",
      "2024-02-10 04:11:56.235002: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 4586471424 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I: 0.02715628594455579 entropy: 16.008635804468483 khat>0.7: 12\n",
      "LL: 0.029092386196232285 entropy: 15.575058021931957 khat>0.7: 38\n",
      "KL: 0.029092386196232285 entropy: 15.998163500488719 khat>0.7: 22\n",
      "Var: 0.030714113091867182 entropy: 16.001419969716643 khat>0.7: 22\n"
     ]
    }
   ],
   "source": [
    "def entropy(probs):\n",
    "    return -tf.math.xlogy(probs, probs)\n",
    "\n",
    "\n",
    "def adaptive_is_loo(self, data, params, hbar=1.0, variational=True):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        data (_type_): _description_\n",
    "        params (_type_): _description_\n",
    "        hbar (float, optional): _description_. Defaults to 1.0.\n",
    "        variational (bool, optional):\n",
    "            Should we trust the variational approximation?\n",
    "            If False, assumes that one is passing in all the data at once in a single batch.\n",
    "            Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "\n",
    "    # scaled (theta - bar(theta))/Sigma\n",
    "    c = self.slab_scale * tf.math.sqrt(params[\"caux\"])\n",
    "    lambda_tilde = tf.math.sqrt(\n",
    "        c**2\n",
    "        * params[\"lambda\"] ** 2\n",
    "        / (c**2 + params[\"tau\"] ** 2 * params[\"lambda\"] ** 2)\n",
    "    )\n",
    "    beta = params[\"z\"] * lambda_tilde * params[\"tau\"]\n",
    "    intercept = params[\"beta0\"]\n",
    "    X = tf.cast(data[\"X\"], self.dtype)\n",
    "    y = tf.cast(data[\"y\"], self.dtype)[:, 0]\n",
    "    mu = beta[..., tf.newaxis, :] * X\n",
    "    mu = tf.reduce_sum(mu, -1) + params[\"beta0\"]\n",
    "    sigma = tf.math.sigmoid(mu)\n",
    "    ell = y * (sigma) + (1 - y) * (1 - sigma)\n",
    "    log_ell = tf.math.xlogy(y, sigma) + tf.math.xlogy(1 - y, 1 - sigma)\n",
    "    log_ell_prime = y * (1 - sigma) - (1 - y) * sigma\n",
    "    log_ell_doubleprime = -sigma * (1 - sigma)\n",
    "    _, khat0 = nppsis.psislw(-log_ell)\n",
    "\n",
    "    \"\"\"\n",
    "    sigma.shape is samples x datapoints\n",
    "    \"\"\"\n",
    "\n",
    "    # compute # \\nabla\\log\\pi(\\btheta|\\calD)\n",
    "    if variational:\n",
    "        # \\nabla\\log\\pi = -\\Sigma^{-1}(theta - \\bar{\\theta})\n",
    "        grad_log_pi = tf.concat(\n",
    "            [\n",
    "                -(intercept - self.surrogate_distribution.model[\"intercept__\"].mean())\n",
    "                / self.surrogate_distribution.model[\"intercept__\"].variance(),\n",
    "                -(beta - self.surrogate_distribution.model[\"beta__\"].mean())\n",
    "                / self.surrogate_distribution.model[\"beta__\"].variance(),\n",
    "            ],\n",
    "            axis=-1,\n",
    "        )\n",
    "        intercept_sd = (\n",
    "            self.surrogate_distribution.model[\"intercept__\"].variance() ** 0.5\n",
    "        )\n",
    "        beta_sd = self.surrogate_distribution.model[\"beta__\"].variance() ** 0.5\n",
    "\n",
    "        log_pi = self.surrogate_distribution.model[\"beta__\"].log_prob(\n",
    "            params[\"beta__\"]\n",
    "        ) + self.surrogate_distribution.model[\"intercept__\"].log_prob(\n",
    "            params[\"intercept__\"]\n",
    "        )\n",
    "        log_pi -= tf.reduce_max(log_pi, axis=0)\n",
    "        # log_pi.shape: [samples]\n",
    "    else:\n",
    "        \"\"\"\n",
    "        Recall Bayes rule:\n",
    "        \\log pi(\\btheta|\\calD) = \\sum_i\\log ell_i(\\btheta) + \\log\\pi(\\btheta) + const\n",
    "\n",
    "        so\n",
    "        \\nabla\\log\\pi(\\btheta|\\calD) = \\sum_i (ell_i)'x + grad\\log\\pi(\\btheta)\n",
    "\n",
    "        \"\"\"\n",
    "        log_prior = self.prior_distribution.log_prob_parts(params)\n",
    "        log_prior = log_prior[\"z\"] + log_prior[\"beta0\"]\n",
    "\n",
    "        log_pi = tf.reduce_sum(log_ell, axis=1, keepdims=True)[:, 0]\n",
    "\n",
    "        # pi \\propto\n",
    "        grad_log_pi = tf.concat(\n",
    "            [\n",
    "                tf.reduce_sum(log_ell_prime[..., tf.newaxis], axis=1, keepdims=True),\n",
    "                tf.reduce_sum(\n",
    "                    log_ell_prime[..., tf.newaxis] * X, axis=1, keepdims=True\n",
    "                ),\n",
    "            ],\n",
    "            axis=-1,\n",
    "        )\n",
    "\n",
    "        grad_log_prior = -0.5 * tf.concat(\n",
    "            [(params[\"beta0\"] / self.scale_icept) ** 2, (params[\"z\"]) ** 2],\n",
    "            axis=-1,\n",
    "        )\n",
    "        grad_log_pi += grad_log_prior[:, tf.newaxis, :]\n",
    "\n",
    "        intercept_sd = tf.math.reduce_std(intercept, 0, keepdims=True)\n",
    "        beta_sd = tf.math.reduce_std(beta, 0, keepdims=True)\n",
    "\n",
    "    # log-likelihood descent\n",
    "\n",
    "    def T_ll():\n",
    "        Q_beta = -log_ell_prime[..., tf.newaxis] * X\n",
    "        Q_intercept = -log_ell_prime[..., tf.newaxis]\n",
    "\n",
    "        standardized = tf.concat(\n",
    "            [Q_beta / beta_sd, Q_intercept / intercept_sd], axis=-1\n",
    "        )\n",
    "        standardized = tf.reduce_max(tf.math.abs(standardized), axis=-1)\n",
    "        standardized = tf.reduce_max(standardized, axis=0, keepdims=True)[\n",
    "            ..., tf.newaxis\n",
    "        ]\n",
    "\n",
    "        h = hbar / standardized\n",
    "        logJ = tf.math.log1p(\n",
    "            tf.math.abs(\n",
    "                h\n",
    "                * (1 + tf.math.reduce_sum(X**2, -1, keepdims=True))[tf.newaxis, :, :]\n",
    "                * (sigma * (1 - sigma))[..., tf.newaxis]\n",
    "            )[..., 0]\n",
    "        )\n",
    "        beta_ll = beta[..., tf.newaxis, :] + h * Q_beta\n",
    "        intercept_ll = intercept[..., tf.newaxis, :] + h * Q_intercept\n",
    "        return beta_ll, intercept_ll, logJ\n",
    "\n",
    "    def T_kl():\n",
    "        log_pi_ = log_pi - tf.reduce_max(log_pi, axis=0, keepdims=True)\n",
    "        Q_beta = ((-1) ** y * tf.math.exp(log_pi_[..., tf.newaxis] + mu * (1 - 2 * y)))[\n",
    "            ..., tf.newaxis\n",
    "        ] * X\n",
    "        Q_intercept = (\n",
    "            ((-1) ** y) * tf.math.exp(log_pi_[..., tf.newaxis] + mu * (1 - 2 * y))\n",
    "        )[..., tf.newaxis]\n",
    "\n",
    "        dQ = (-1) ** y[tf.newaxis, :] * tf.math.exp(\n",
    "            log_pi_[..., tf.newaxis] + mu * (1 - 2 * y[tf.newaxis, :])\n",
    "        )\n",
    "        dQ *= (\n",
    "            grad_log_pi[..., 0]\n",
    "            + (1 - 2 * y)[tf.newaxis, :]\n",
    "            + tf.reduce_sum(\n",
    "                X\n",
    "                * (\n",
    "                    grad_log_pi[..., 1:]\n",
    "                    + (1 - 2 * y)[:, tf.newaxis] * X[tf.newaxis, ...]\n",
    "                ),\n",
    "                axis=-1,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        standardized = tf.concat(\n",
    "            [Q_beta / beta_sd, Q_intercept / intercept_sd], axis=-1\n",
    "        )\n",
    "        standardized = tf.reduce_max(tf.math.abs(standardized), axis=-1)\n",
    "        standardized = tf.reduce_max(standardized, axis=0, keepdims=True)[\n",
    "            ..., tf.newaxis\n",
    "        ]\n",
    "\n",
    "        h = hbar / standardized\n",
    "\n",
    "        intercept_kl = intercept[..., tf.newaxis] + h * Q_intercept\n",
    "        beta_kl = beta[..., tf.newaxis, :] + h * Q_beta\n",
    "\n",
    "        logJ = tf.math.log1p(tf.math.abs(h[..., 0] * dQ))\n",
    "        return beta_kl, intercept_kl, logJ\n",
    "\n",
    "    # variance descent -(log ell)'/l\n",
    "\n",
    "    def T_I():\n",
    "        Q = tf.zeros_like(log_ell)\n",
    "        return (\n",
    "            beta[:, tf.newaxis, :] + Q[..., tf.newaxis],\n",
    "            intercept[..., tf.newaxis] + Q[..., tf.newaxis],\n",
    "            tf.zeros_like(Q),\n",
    "        )\n",
    "\n",
    "    def T_var():\n",
    "        log_pi_ = log_pi - tf.reduce_max(log_pi, axis=0, keepdims=True)\n",
    "\n",
    "        Q_beta = (\n",
    "            (-1) ** y * tf.math.exp(log_pi_[..., tf.newaxis] + 2 * mu * (1 - 2 * y))\n",
    "        )[..., tf.newaxis] * X\n",
    "        Q_intercept = (\n",
    "            (-1) ** y * tf.math.exp(log_pi_[..., tf.newaxis] + 2 * mu * (1 - 2 * y))\n",
    "        )[..., tf.newaxis]\n",
    "\n",
    "        dQ = (\n",
    "            (-1) ** y[tf.newaxis, :]\n",
    "            * tf.math.exp(\n",
    "                log_pi_[..., tf.newaxis] + 2 * mu * (1 - 2 * y[tf.newaxis, :])\n",
    "            )\n",
    "            * (\n",
    "                grad_log_pi[..., 0]\n",
    "                + (1 - 2 * y)[tf.newaxis, :]\n",
    "                + tf.reduce_sum(\n",
    "                    X * (grad_log_pi[..., 1:] + 2 * (1 - 2 * y)[:, tf.newaxis] * X),\n",
    "                    axis=-1,\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "\n",
    "        standardized = tf.concat(\n",
    "            [Q_beta / beta_sd, Q_intercept / intercept_sd], axis=-1\n",
    "        )\n",
    "        standardized = tf.reduce_max(tf.math.abs(standardized), axis=-1)\n",
    "        standardized = tf.reduce_max(standardized, axis=0, keepdims=True)[\n",
    "            ..., tf.newaxis\n",
    "        ]\n",
    "\n",
    "        h = hbar / standardized\n",
    "\n",
    "        intercept_kl = intercept[..., tf.newaxis, :] + h * Q_intercept\n",
    "        beta_kl = beta[..., tf.newaxis, :] + h * Q_beta\n",
    "\n",
    "        logJ = tf.math.log1p(tf.math.abs(h[..., 0] * dQ))\n",
    "        return beta_kl, intercept_kl, logJ\n",
    "\n",
    "    def IS(Q):\n",
    "        beta_new, intercept_new, logJ = Q()\n",
    "        mu_new = tf.reduce_sum(beta_new * X, axis=-1) + intercept_new[..., 0]\n",
    "        sigma_new = tf.math.sigmoid(mu_new)\n",
    "        ell_new = y * (sigma_new) + (1 - y) * (1 - sigma_new)\n",
    "        log_ell_new = tf.math.xlogy(y, sigma_new) + tf.math.xlogy(1 - y, 1 - sigma_new)\n",
    "        c = self.slab_scale * tf.math.sqrt(params[\"caux\"])\n",
    "        lambda_tilde = tf.math.sqrt(\n",
    "            c**2\n",
    "            * params[\"lambda\"] ** 2\n",
    "            / (c**2 + params[\"tau\"] ** 2 * params[\"lambda\"] ** 2)\n",
    "        )\n",
    "        transformed = params.copy()\n",
    "        transformed[\"z\"] = beta_new / (\n",
    "            lambda_tilde[:, tf.newaxis, :] * params[\"tau\"][..., tf.newaxis]\n",
    "        )\n",
    "        transformed[\"beta0\"] = intercept_new\n",
    "\n",
    "        if variational:\n",
    "            # We trust the variational approximation, so \\hat{pi} = pi\n",
    "            # N_samples x N_data\n",
    "            delta_log_pi = (\n",
    "                self.surrogate_distribution.log_prob(transformed)\n",
    "                - log_pi[:, tf.newaxis]\n",
    "            )\n",
    "            delta_log_pi = delta_log_pi - tf.reduce_max(\n",
    "                delta_log_pi, axis=0, keepdims=True\n",
    "            )\n",
    "            pass\n",
    "        else:\n",
    "            # we don't trust the variational approximation\n",
    "            # Need to compute log_pi directly by summing over the likelihood\n",
    "\n",
    "            ell_cross = tf.math.sigmoid(\n",
    "                tf.reduce_sum(beta_new[..., tf.newaxis, :] * X, -1) + intercept_new\n",
    "            )\n",
    "            ell_cross = tf.math.xlogy(y, ell_cross) + tf.math.xlogy(\n",
    "                1 - y, 1 - ell_cross\n",
    "            )\n",
    "            ell_cross = tf.math.reduce_sum(ell_cross, axis=-1)\n",
    "\n",
    "            log_prior_new = self.prior_distribution.log_prob_parts(transformed)\n",
    "            log_prior_new = log_prior_new[\"z\"] + log_prior_new[\"beta0\"]\n",
    "            log_pi_new = ell_cross\n",
    "            delta_log_prior = log_prior_new - log_prior[:, tf.newaxis]\n",
    "            # Incorporate the prior\n",
    "            delta_log_pi = log_pi_new - log_pi[:, tf.newaxis] + delta_log_prior\n",
    "        log_eta_weights = delta_log_pi - log_ell_new + logJ\n",
    "        log_eta_weights = log_eta_weights - tf.reduce_max(log_eta_weights, axis=0)\n",
    "        psis_weights, khat = nppsis.psislw(log_eta_weights)\n",
    "        _, khat_test = nppsis.psislw(-log_ell_new - tf.reduce_max(-log_ell_new, axis=0))\n",
    "\n",
    "        eta_weights = tf.math.exp(log_eta_weights)\n",
    "        eta_weights = eta_weights / tf.reduce_sum(eta_weights, axis=0, keepdims=True)\n",
    "\n",
    "        psis_weights = tf.math.exp(psis_weights)\n",
    "        psis_weights = psis_weights / tf.math.reduce_sum(\n",
    "            psis_weights, axis=0, keepdims=True\n",
    "        )\n",
    "\n",
    "        weight_entropy = self.entropy(eta_weights)\n",
    "        psis_entropy = self.entropy(psis_weights)\n",
    "\n",
    "        p_loo_new = tf.reduce_sum(sigma_new * eta_weights, axis=0)\n",
    "        p_loo_psis = tf.reduce_sum(sigma_new * psis_weights, axis=0)\n",
    "        p_loo_sd = tf.math.reduce_std(sigma_new * eta_weights, axis=0)\n",
    "        ll_loo_new = tf.reduce_sum(eta_weights * ell_new, axis=0)\n",
    "        ll_loo_psis = tf.reduce_sum(psis_weights * ell_new, axis=0)\n",
    "        ll_loo_sd = tf.math.reduce_std(eta_weights * ell_new, axis=0)\n",
    "        return (\n",
    "            eta_weights,\n",
    "            psis_weights,\n",
    "            p_loo_new,\n",
    "            p_loo_sd,\n",
    "            ll_loo_new,\n",
    "            ll_loo_sd,\n",
    "            weight_entropy,\n",
    "            khat,\n",
    "            p_loo_psis,\n",
    "            ll_loo_psis,\n",
    "        )\n",
    "\n",
    "    (\n",
    "        eta_I,\n",
    "        eta_I_psis,\n",
    "        p_loo_I,\n",
    "        p_loo_I_sd,\n",
    "        ll_loo_I,\n",
    "        ll_loo_I_sd,\n",
    "        S_I,\n",
    "        k_I,\n",
    "        p_psis_I,\n",
    "        ll_psis_I,\n",
    "    ) = IS(T_I)\n",
    "\n",
    "    (\n",
    "        eta_kl,\n",
    "        eta_kl_psis,\n",
    "        p_loo_kl,\n",
    "        p_loo_kl_sd,\n",
    "        ll_loo_kl,\n",
    "        ll_loo_kl_sd,\n",
    "        S_kl,\n",
    "        k_kl,\n",
    "        p_psis_kl,\n",
    "        ll_psis_kl,\n",
    "    ) = IS(T_kl)\n",
    "\n",
    "    (\n",
    "        eta_var,\n",
    "        eta_var_psis,\n",
    "        p_loo_var,\n",
    "        p_loo_var_sd,\n",
    "        ll_loo_var,\n",
    "        ll_loo_var_sd,\n",
    "        S_var,\n",
    "        k_var,\n",
    "        p_psis_var,\n",
    "        ll_psis_var,\n",
    "    ) = IS(T_var)\n",
    "    (\n",
    "        eta_ll,\n",
    "        eta_ll_psis,\n",
    "        p_loo_ll,\n",
    "        p_loo_ll_sd,\n",
    "        ll_loo_ll,\n",
    "        ll_loo_ll_sd,\n",
    "        S_ll,\n",
    "        k_ll,\n",
    "        p_psis_ll,\n",
    "        ll_psis_ll,\n",
    "    ) = IS(T_ll)\n",
    "    # kl descent\n",
    "\n",
    "    return {\n",
    "        \"I\": {\n",
    "            \"p_loo\": p_loo_I,\n",
    "            \"p_loo_sd\": p_loo_I_sd,\n",
    "            \"ll_loo\": ll_loo_I,\n",
    "            \"ll_loo_sd\": ll_loo_I_sd,\n",
    "            \"S\": S_I,\n",
    "            \"khat\": k_I,\n",
    "            \"p_psis\": p_psis_I,\n",
    "            \"ll_psis\": ll_psis_I,\n",
    "        },\n",
    "        \"KL\": {\n",
    "            \"p_loo\": p_loo_kl,\n",
    "            \"p_loo_sd\": p_loo_kl_sd,\n",
    "            \"ll_loo\": ll_loo_kl,\n",
    "            \"ll_loo_sd\": ll_loo_kl_sd,\n",
    "            \"S\": S_kl,\n",
    "            \"khat\": k_kl,\n",
    "            \"p_psis\": p_psis_kl,\n",
    "            \"ll_psis\": ll_psis_kl,\n",
    "        },\n",
    "        \"LL\": {\n",
    "            \"p_loo\": p_loo_kl,\n",
    "            \"p_loo_sd\": p_loo_kl_sd,\n",
    "            \"ll_loo\": ll_loo_kl,\n",
    "            \"ll_loo_sd\": ll_loo_kl_sd,\n",
    "            \"S\": S_ll,\n",
    "            \"khat\": k_ll,\n",
    "            \"p_psis\": p_psis_ll,\n",
    "            \"ll_psis\": ll_psis_ll,\n",
    "        },\n",
    "        \"Var\": {\n",
    "            \"p_loo\": p_loo_var,\n",
    "            \"p_loo_sd\": p_loo_var_sd,\n",
    "            \"ll_loo\": ll_loo_var,\n",
    "            \"ll_loo_sd\": ll_loo_var_sd,\n",
    "            \"S\": S_var,\n",
    "            \"khat\": k_var,\n",
    "            \"p_psis\": p_psis_var,\n",
    "            \"ll_psis\": ll_psis_var,\n",
    "        },\n",
    "    }\n",
    "\n",
    "\n",
    "loo = adaptive_is_loo(lr_model, batch, params, 1e-5, variational=False)\n",
    "\n",
    "# loo = adaptive_is_loo(lr_model, test_batch, param_test, 0.01, variational=False)\n",
    "\n",
    "\n",
    "for T in [\"I\", \"LL\", \"KL\", \"Var\"]:\n",
    "    print(\n",
    "        f\"{T}: {np.sqrt(np.sum(loo[T]['p_loo_sd']**2))} entropy: {np.sqrt(np.sum(loo[T]['S']))} khat>0.7: {np.sum(loo[T]['khat']>0.7)}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3,  9, 15, 17, 21, 28, 29, 33, 44, 48, 49, 51])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "khat = pd.DataFrame({\"khat\": loo[\"I\"]['khat']})\n",
    "khat = khat.loc[khat.khat> 0.7] \n",
    "ndx = np.array(khat.index)\n",
    "ndx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 64\n",
      "rho=1\n",
      "\n",
      "rho=0.5\n",
      "\n",
      "rho=0.1\n",
      "\n",
      "rho=0.01\n",
      "\n",
      "rho=0.001\n",
      "\n",
      "rho=0.0001\n",
      "\n",
      "rho=1e-05\n",
      "\n",
      "rho=1e-06\n",
      "\n",
      "rho=1e-07\n",
      "\n",
      "Samples: 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-10 04:12:13.859705: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 4586471424 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rho=1\n",
      "\n",
      "rho=0.5\n",
      "\n",
      "rho=0.1\n",
      "\n",
      "rho=0.01\n",
      "\n",
      "rho=0.001\n",
      "\n",
      "rho=0.0001\n",
      "\n",
      "rho=1e-05\n",
      "\n",
      "rho=1e-06\n",
      "\n",
      "rho=1e-07\n",
      "\n"
     ]
    }
   ],
   "source": [
    "h_vals = [1, 0.5, 1e-1, 1e-2, 1e-3, 1e-4, 1e-5, 1e-6, 1e-7]\n",
    "loo_khat = {}\n",
    "reduced_ndx = {}\n",
    "high_khat_ndx = {}\n",
    "n_sample = [64, 128]\n",
    "\n",
    "for n_samples in n_sample:\n",
    "    sample_ndx = choices(range(2000), k=n_samples)\n",
    "    reduced_ndx[n_samples] = []\n",
    "    high_khat_ndx[n_samples] = {}\n",
    "    print(f\"Samples: {n_samples}\")\n",
    "    loo_khat[n_samples] = {}\n",
    "    params = fit.stan_variables()\n",
    "\n",
    "    params['c'] = params['c'][:, tf.newaxis]\n",
    "    params['tau'] = params['tau'][:, tf.newaxis]\n",
    "    params['caux'] = params['caux'][:, tf.newaxis]\n",
    "    params['beta0'] = params['beta0'][:, tf.newaxis]\n",
    "    params = {k: v[sample_ndx] for k, v in params.items()}\n",
    "    \n",
    "    records = []\n",
    "\n",
    "    for h in h_vals:\n",
    "        loo_khat[n_samples][h] = {}\n",
    "        loo = adaptive_is_loo(lr_model, batch, params, h, variational=False)\n",
    "        khat = pd.DataFrame({\"khat\": loo[\"I\"]['khat']})\n",
    "        khat = khat.loc[khat.khat> 0.7] \n",
    "        ndx = np.array(khat.index)\n",
    "        high_khat_ndx[n_samples][h] = np.where((loo['I']['khat']>0.7))\n",
    "        print(f\"rho={h}\\n\")\n",
    "        for T in [\"I\", \"LL\", \"KL\", \"Var\"]:\n",
    "            loo_khat[n_samples][h][T] = np.array(loo[T]['khat'])\n",
    "            \n",
    "            records += [\n",
    "                {\n",
    "                    \"h\": h,\n",
    "                    \"T\": T,\n",
    "                    \"S\": n_samples,\n",
    "                    \n",
    "                }\n",
    "            ]\n",
    "            # print(f\"Transform: {T}\")\n",
    "            #print(\n",
    "            #    f\"V: {np.sqrt(np.sum(loo[T]['p_loo_sd']**2))} S: {np.sqrt(np.sum(loo[T]['S']))} khat>0.7: {np.sum(loo[T]['khat']>0.7)}\"\n",
    "            #)\n",
    "            #print(f\"k-hat reduction for these k-hat>0.7 obs: {np.where((loo['I']['khat'] - loo[T]['khat']>0) * (loo['I']['khat']>0.7))}\")\n",
    "            reduced_ndx[n_samples] += [np.where((loo['I']['khat'] - loo[T]['khat']>0) * (loo['I']['khat']>0.7) * (loo[T]['khat']<0.7))]\n",
    "            #print(f\"k-hat reduction to below 0.7 for these k-hat>0.7 obs: {reduced_ndx[n_samples][-1]}\")\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n_sample' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n_samples \u001b[38;5;129;01min\u001b[39;00m \u001b[43mn_sample\u001b[49m:\n\u001b[1;32m      2\u001b[0m     high_ndx_ \u001b[38;5;241m=\u001b[39m (chain\u001b[38;5;241m.\u001b[39mfrom_iterable([x[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mflatten()\u001b[38;5;241m.\u001b[39mtolist() \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m high_khat_ndx[n_samples]\u001b[38;5;241m.\u001b[39mvalues()]))\n\u001b[1;32m      3\u001b[0m     reduced_ndx_ \u001b[38;5;241m=\u001b[39m (chain\u001b[38;5;241m.\u001b[39mfrom_iterable([x[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mflatten()\u001b[38;5;241m.\u001b[39mtolist() \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m reduced_ndx[n_samples]]))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'n_sample' is not defined"
     ]
    }
   ],
   "source": [
    "for n_samples in n_sample:\n",
    "    high_ndx_ = (chain.from_iterable([x[0].flatten().tolist() for x in high_khat_ndx[n_samples].values()]))\n",
    "    reduced_ndx_ = (chain.from_iterable([x[0].flatten().tolist() for x in reduced_ndx[n_samples]]))\n",
    "    high_ndx_ = set(high_ndx_)\n",
    "    reduced_ndx_ = set(reduced_ndx_)\n",
    "    print(len(high_ndx_), len(reduced_ndx_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 13\n",
      "16 14\n"
     ]
    }
   ],
   "source": [
    "for n_samples in n_sample:\n",
    "    high_ndx_ = (chain.from_iterable([x[0].flatten().tolist() for x in high_khat_ndx[n_samples].values()]))\n",
    "    reduced_ndx_ = (chain.from_iterable([x[0].flatten().tolist() for x in reduced_ndx[n_samples]]))\n",
    "    high_ndx_ = set(high_ndx_)\n",
    "    reduced_ndx_ = set(reduced_ndx_)\n",
    "    print(len(high_ndx_), len(reduced_ndx_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndx = np.where(loo_khat[128][1]['I']>0.7)\n",
    "loo_khat[128][1][\"I\"].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.65408515,  0.8346707 ,  0.40190678,  0.6176137 ,  0.01239853,\n",
       "        0.29415639,  0.87093774,  0.51754589,  0.27877207,  0.82677692,\n",
       "        0.57137833,  0.48823111,  0.35356194,  0.546493  ,  0.23275198,\n",
       "        0.58025734,  0.15419805,  1.0019735 ,  0.26171676,  0.12506481,\n",
       "        0.54198525,  0.72778185,  0.49046819,  1.0119757 ,  0.04178649,\n",
       "        1.11444325,  0.59726703,  0.30080367,  1.18984537,  0.84376898,\n",
       "        1.02526788,  0.7806859 ,  0.46951341,  0.99952059,  0.41118995,\n",
       "        0.0198669 ,  0.28989138,  0.57214156,  1.44682822,  0.23460293,\n",
       "        0.85442693,  0.56409529,  0.29625234,  1.27099606,  0.50240233,\n",
       "        0.18606137,  0.56533367,  0.34241251, -0.10057692,  0.63346162,\n",
       "        0.58486646,  1.60226088,  0.40176128,  0.58999429])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loo_khat[128][.1]['I']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>64</th>\n",
       "      <th>128</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.000000e+00</th>\n",
       "      <td>{'I': [0.4521478089482797, 0.24478945795110962...</td>\n",
       "      <td>{'I': [0.6540851487270996, 0.8346707041835684,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.000000e-01</th>\n",
       "      <td>{'I': [0.4521478089482797, 0.24478945795110962...</td>\n",
       "      <td>{'I': [0.6540851487270996, 0.8346707041835684,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.000000e-01</th>\n",
       "      <td>{'I': [0.4521478089482797, 0.24478945795110962...</td>\n",
       "      <td>{'I': [0.6540851487270996, 0.8346707041835684,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.000000e-02</th>\n",
       "      <td>{'I': [0.4521478089482797, 0.24478945795110962...</td>\n",
       "      <td>{'I': [0.6540851487270996, 0.8346707041835684,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.000000e-03</th>\n",
       "      <td>{'I': [0.4521478089482797, 0.24478945795110962...</td>\n",
       "      <td>{'I': [0.6540851487270996, 0.8346707041835684,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.000000e-04</th>\n",
       "      <td>{'I': [0.4521478089482797, 0.24478945795110962...</td>\n",
       "      <td>{'I': [0.6540851487270996, 0.8346707041835684,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.000000e-05</th>\n",
       "      <td>{'I': [0.4521478089482797, 0.24478945795110962...</td>\n",
       "      <td>{'I': [0.6540851487270996, 0.8346707041835684,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.000000e-06</th>\n",
       "      <td>{'I': [0.4521478089482797, 0.24478945795110962...</td>\n",
       "      <td>{'I': [0.6540851487270996, 0.8346707041835684,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.000000e-07</th>\n",
       "      <td>{'I': [0.4521478089482797, 0.24478945795110962...</td>\n",
       "      <td>{'I': [0.6540851487270996, 0.8346707041835684,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                            64   \\\n",
       "1.000000e+00  {'I': [0.4521478089482797, 0.24478945795110962...   \n",
       "5.000000e-01  {'I': [0.4521478089482797, 0.24478945795110962...   \n",
       "1.000000e-01  {'I': [0.4521478089482797, 0.24478945795110962...   \n",
       "1.000000e-02  {'I': [0.4521478089482797, 0.24478945795110962...   \n",
       "1.000000e-03  {'I': [0.4521478089482797, 0.24478945795110962...   \n",
       "1.000000e-04  {'I': [0.4521478089482797, 0.24478945795110962...   \n",
       "1.000000e-05  {'I': [0.4521478089482797, 0.24478945795110962...   \n",
       "1.000000e-06  {'I': [0.4521478089482797, 0.24478945795110962...   \n",
       "1.000000e-07  {'I': [0.4521478089482797, 0.24478945795110962...   \n",
       "\n",
       "                                                            128  \n",
       "1.000000e+00  {'I': [0.6540851487270996, 0.8346707041835684,...  \n",
       "5.000000e-01  {'I': [0.6540851487270996, 0.8346707041835684,...  \n",
       "1.000000e-01  {'I': [0.6540851487270996, 0.8346707041835684,...  \n",
       "1.000000e-02  {'I': [0.6540851487270996, 0.8346707041835684,...  \n",
       "1.000000e-03  {'I': [0.6540851487270996, 0.8346707041835684,...  \n",
       "1.000000e-04  {'I': [0.6540851487270996, 0.8346707041835684,...  \n",
       "1.000000e-05  {'I': [0.6540851487270996, 0.8346707041835684,...  \n",
       "1.000000e-06  {'I': [0.6540851487270996, 0.8346707041835684,...  \n",
       "1.000000e-07  {'I': [0.6540851487270996, 0.8346707041835684,...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(loo_khat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reduced_ndx_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
