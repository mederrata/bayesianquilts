{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "from skimpy import skim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-03 18:00:42.522874: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-03 18:00:42.548746: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-03 18:00:42.548772: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-03 18:00:42.549755: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-03 18:00:42.554491: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-03 18:00:42.554855: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-03 18:00:43.147082: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "from bayesianquilts.models.logistic_regression import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.15.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.23.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfp.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the dataset\n",
    "\n",
    "Using the example from here: https://www.tensorflow.org/guide/core/logistic_regression_core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch dataset \n",
    "cdc_diabetes_health_indicators = fetch_ucirepo(id=891) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = cdc_diabetes_health_indicators.data.features \n",
    "y = cdc_diabetes_health_indicators.data.targets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = (X - X.min())/X.max()\n",
    "n = X_scaled.shape[0]\n",
    "p = X_scaled.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = LogisticRegression(dim_regressors=p, regression_interact=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intercept__': <tf.Tensor: shape=(1, 1, 1), dtype=float64, numpy=array([[[0.00606185]]])>,\n",
       " 'beta__': <tf.Tensor: shape=(1, 1, 21), dtype=float64, numpy=\n",
       " array([[[ 0.0112644 , -0.02000487, -0.01019887, -0.00386574,\n",
       "          -0.00134389,  0.00517637, -0.00860098,  0.00071033,\n",
       "          -0.01562623,  0.00162767, -0.01155714,  0.01747173,\n",
       "           0.00244064, -0.00272712, -0.00218558,  0.00130492,\n",
       "           0.00059278,  0.0183492 , -0.01033788,  0.01339786,\n",
       "          -0.00924953]]])>}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 3171"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfdata = tf.data.Dataset.from_tensor_slices({'X': X_scaled, 'y':y})\n",
    "\n",
    "def data_factory():\n",
    "    out = tfdata.shuffle(4000).batch(batch_size)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved a checkpoint: /tmp/tfcheckpoints/9fc88aaf-ae9c-47ad-bc76-dd653e82f9b3/9fc88aaf-ae9c-47ad-bc76-dd653e82f9b3-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for %: 'int' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m losses \u001b[38;5;241m=\u001b[39m \u001b[43mlr_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatches_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheck_every\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_decay_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m400\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_plateau_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0015\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/bayesianquilts/bayesianquilts/model.py:68\u001b[0m, in \u001b[0;36mBayesianModel.fit\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_calibrate_minibatch_advi\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/bayesianquilts/bayesianquilts/model.py:151\u001b[0m, in \u001b[0;36mBayesianModel._calibrate_minibatch_advi\u001b[0;34m(self, batched_data_factory, batch_size, dataset_size, num_steps, learning_rate, opt, abs_tol, rel_tol, clip_value, clip_by, max_decay_steps, lr_decay_factor, check_every, set_expectations, sample_size, sample_batches, trainable_variables, unormalized_log_prob_fn, accumulate_batches, batches_per_step, temp_dir, test_fn, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m     losses \u001b[38;5;241m=\u001b[39m minibatch_fit_surrogate_posterior(\n\u001b[1;32m    124\u001b[0m         target_log_prob_fn\u001b[38;5;241m=\u001b[39munormalized_log_prob_fn\n\u001b[1;32m    125\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m unormalized_log_prob_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    148\u001b[0m     )\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m losses\n\u001b[0;32m--> 151\u001b[0m losses \u001b[38;5;241m=\u001b[39m \u001b[43mrun_approximation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m set_expectations:\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misnan(losses[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misinf(losses[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])):\n",
      "File \u001b[0;32m~/workspace/bayesianquilts/bayesianquilts/model.py:123\u001b[0m, in \u001b[0;36mBayesianModel._calibrate_minibatch_advi.<locals>.run_approximation\u001b[0;34m(num_steps)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_approximation\u001b[39m(num_steps):\n\u001b[0;32m--> 123\u001b[0m     losses \u001b[38;5;241m=\u001b[39m \u001b[43mminibatch_fit_surrogate_posterior\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget_log_prob_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munormalized_log_prob_fn\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43munormalized_log_prob_fn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m    126\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munormalized_log_prob\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m        \u001b[49m\u001b[43msurrogate_posterior\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msurrogate_distribution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataset_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_batches\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_batches\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_decay_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_decay_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecay_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr_decay_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m        \u001b[49m\u001b[43mabs_tol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mabs_tol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrel_tol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrel_tol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclip_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclip_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclip_by\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclip_by\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_every\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_every\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccumulate_batches\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccumulate_batches\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatches_per_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatches_per_step\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrainable_variables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatched_data_factory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatched_data_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m losses\n",
      "File \u001b[0;32m~/workspace/bayesianquilts/bayesianquilts/vi/minibatch.py:181\u001b[0m, in \u001b[0;36mminibatch_fit_surrogate_posterior\u001b[0;34m(target_log_prob_fn, surrogate_posterior, batched_data_factory, batch_size, dataset_size, num_steps, trace_fn, sample_size, sample_batches, check_every, decay_rate, learning_rate, clip_value, clip_by, trainable_variables, jit_compile, accumulate_batches, batches_per_step, abs_tol, rel_tol, strategy, name, test_fn, **kwargs)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"This becomes the loss function called in the\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;124;03m    optimization loop\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;124;03m        [type] -- [description]\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m minibatch_mc_variational_loss(\n\u001b[1;32m    169\u001b[0m         target_log_prob_fn,\n\u001b[1;32m    170\u001b[0m         surrogate_posterior,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    179\u001b[0m     )\n\u001b[0;32m--> 181\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbatched_minimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcomplete_variational_loss_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatched_data_factory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatched_data_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrace_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrace_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainable_variables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m    \u001b[49m\u001b[43mabs_tol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mabs_tol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrel_tol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrel_tol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclip_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclip_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclip_by\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclip_by\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_batches\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccumulate_batches\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatches_per_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatches_per_step\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecay_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecay_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheck_every\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_every\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/bayesianquilts/bayesianquilts/util.py:163\u001b[0m, in \u001b[0;36mbatched_minimize\u001b[0;34m(loss_fn, batched_data_factory, batches_per_step, num_steps, max_plateau_epochs, plateau_epochs_til_restore, abs_tol, rel_tol, trainable_variables, trace_fn, learning_rate, decay_rate, max_decay_steps, checkpoint_name, processing_fn, name, check_every, clip_value, clip_norm, test_fn, verbose, debug, temp_dir, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n_batch, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(data_factory):\n\u001b[0;32m--> 163\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mn_batch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatches_per_step\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    164\u001b[0m         \u001b[38;5;66;03m# this batch is the start of a gradient step\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \n\u001b[1;32m    166\u001b[0m         \u001b[38;5;66;03m#  apply the grad\u001b[39;00m\n\u001b[1;32m    167\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (gradient_accumulation \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (np\u001b[38;5;241m.\u001b[39misfinite(batch_loss)):\n\u001b[1;32m    168\u001b[0m             _ \u001b[38;5;241m=\u001b[39m apply_grads(gradient_accumulation, watched_variables)\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for %: 'int' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "losses = lr_model.fit(\n",
    "    data_factory,\n",
    "    dataset_size=n,\n",
    "    batches_per_epoch=int(n/batch_size),\n",
    "    check_every=10,\n",
    "    batch_size=200,\n",
    "    num_epochs=500,\n",
    "    max_decay_steps=400,\n",
    "    max_plateau_epochs=100,\n",
    "    sample_size=32,\n",
    "    learning_rate=0.0015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
