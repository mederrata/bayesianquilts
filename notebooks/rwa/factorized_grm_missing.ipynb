{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Factorized Graded Response Model with Stochastic Imputation\n",
    "\n",
    "This notebook demonstrates fitting a **FactorizedGRModel** from `bayesianquilts.irt` to the\n",
    "Right-Wing Authoritarianism (RWA) scale dataset, with stochastic imputation of missing responses.\n",
    "\n",
    "Key features shown:\n",
    "- Loading the RWA dataset (22 items, 9 response categories, 2 latent dimensions)\n",
    "- Introducing artificial missingness\n",
    "- Fitting a **MICEBayesianLOO** imputation model\n",
    "- Fitting a FactorizedGRModel **without** imputation (zero-fill baseline)\n",
    "- Fitting a FactorizedGRModel **with** stochastic imputation\n",
    "- Comparing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "os.environ['JAX_PLATFORMS'] = 'cpu'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-header",
   "metadata": {},
   "source": [
    "## 1. Load and Explore the RWA Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayesianquilts.data.rwa import (\n",
    "    get_data, item_keys, item_text, to_reverse, scale_indices\n",
    ")\n",
    "\n",
    "df, num_people = get_data(polars_out=True)\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Number of people: {num_people}\")\n",
    "print(f\"Number of items: {len(item_keys)}\")\n",
    "print(f\"Response categories: 0-8 (9 levels)\")\n",
    "print(f\"\\nScale 1 items ({len(scale_indices[0])} items): {[item_keys[i] for i in scale_indices[0]]}\")\n",
    "print(f\"Scale 2 items ({len(scale_indices[1])} items): {[item_keys[i] for i in scale_indices[1]]}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subsample",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsample for faster fitting in this demo\n",
    "SUBSAMPLE_N = 500\n",
    "rng = np.random.default_rng(42)\n",
    "idx = rng.choice(num_people, size=SUBSAMPLE_N, replace=False)\n",
    "idx.sort()\n",
    "\n",
    "sub_df = df[idx.tolist()]\n",
    "print(f\"Subsample size: {len(sub_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "missing-intro",
   "metadata": {},
   "source": [
    "## 2. Introduce Artificial Missingness\n",
    "\n",
    "The RWA dataset has very low natural missingness (~0.3%). To demonstrate\n",
    "imputation, we randomly mask 15% of responses as missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add-missingness",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "MISSING_RATE = 0.15\n",
    "rng_miss = np.random.default_rng(99)\n",
    "\n",
    "# Start with the subsample and convert -1 (original missing) to NaN\n",
    "sub_df_missing = sub_df.with_columns([\n",
    "    pl.when(pl.col(k) == -1).then(None).otherwise(pl.col(k)).alias(k)\n",
    "    for k in item_keys\n",
    "])\n",
    "\n",
    "# Add artificial MCAR missingness\n",
    "mask_arrays = {}\n",
    "for k in item_keys:\n",
    "    mask = rng_miss.random(SUBSAMPLE_N) < MISSING_RATE\n",
    "    mask_arrays[k] = mask\n",
    "\n",
    "sub_df_missing = sub_df_missing.with_columns([\n",
    "    pl.when(pl.Series(mask_arrays[k])).then(None).otherwise(pl.col(k)).alias(k)\n",
    "    for k in item_keys\n",
    "])\n",
    "\n",
    "# Count missingness\n",
    "total_missing = sum(sub_df_missing[k].null_count() for k in item_keys)\n",
    "total_cells = SUBSAMPLE_N * len(item_keys)\n",
    "print(f\"Total missing: {total_missing}/{total_cells} ({100*total_missing/total_cells:.1f}%)\")\n",
    "print(f\"\\nMissing per item:\")\n",
    "for k in item_keys[:5]:\n",
    "    print(f\"  {k}: {sub_df_missing[k].null_count()}\")\n",
    "print(f\"  ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "response-dist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Response distributions for a few items (observed only)\n",
    "fig, axes = plt.subplots(2, 3, figsize=(12, 6))\n",
    "for ax, k in zip(axes.flat, item_keys[:6]):\n",
    "    vals = sub_df_missing[k].drop_nulls().to_numpy()\n",
    "    ax.hist(vals, bins=np.arange(-0.5, 9.5, 1), edgecolor='black', alpha=0.7)\n",
    "    n_miss = sub_df_missing[k].null_count()\n",
    "    ax.set_title(f'{k} ({n_miss} missing)')\n",
    "    ax.set_xlabel('Response')\n",
    "    ax.set_ylabel('Count')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imputation-header",
   "metadata": {},
   "source": [
    "## 3. Fit a MICEBayesianLOO Imputation Model\n",
    "\n",
    "We fit a Bayesian LOO-CV stacking model that can predict any item from the\n",
    "other observed items. This model will be used during IRT fitting to stochastically\n",
    "fill in missing responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fit-imputation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayesianquilts.imputation.mice_loo import MICEBayesianLOO\n",
    "\n",
    "# Convert to pandas with NaN for missing (MICEBayesianLOO expects pandas)\n",
    "imputation_df = sub_df_missing.select(item_keys).to_pandas()\n",
    "print(f\"Imputation DataFrame shape: {imputation_df.shape}\")\n",
    "print(f\"NaN count: {imputation_df.isna().sum().sum()}\")\n",
    "\n",
    "mice_loo = MICEBayesianLOO(\n",
    "    random_state=42,\n",
    "    prior_scale=1.0,\n",
    "    pathfinder_num_samples=100,\n",
    "    pathfinder_maxiter=50,\n",
    "    batch_size=512,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "mice_loo.fit_loo_models(\n",
    "    X_df=imputation_df,\n",
    "    fit_zero_predictors=True,\n",
    "    n_jobs=-1,\n",
    "    n_top_features=22,  # All items as potential predictors\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "print(f\"\\nFitted variable names: {mice_loo.variable_names[:5]}...\")\n",
    "print(f\"Variable types: {dict(list(mice_loo.variable_types.items())[:5])}...\")\n",
    "print(f\"Zero-predictor models: {len(mice_loo.zero_predictor_results)}\")\n",
    "print(f\"Univariate models: {len(mice_loo.univariate_results)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test-prediction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test a single prediction\n",
    "# Predict Q1 given some observed items\n",
    "observed = {item_keys[i]: float(sub_df_missing[item_keys[i]][0]) \n",
    "            for i in range(1, 22) \n",
    "            if sub_df_missing[item_keys[i]][0] is not None}\n",
    "result = mice_loo.predict(observed, target='Q1', return_details=True)\n",
    "print(f\"Predicted Q1: {result['prediction']:.2f}\")\n",
    "print(f\"Stacking weights: {result['weights']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baseline-header",
   "metadata": {},
   "source": [
    "## 4. Fit FactorizedGRModel WITHOUT Imputation (Baseline)\n",
    "\n",
    "First, fit the model using the default zero-fill strategy for missing data.\n",
    "Missing responses have their log-likelihood zeroed out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prepare-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayesianquilts.irt.factorizedgrm import FactorizedGRModel\n",
    "\n",
    "def make_data_dict(dataframe):\n",
    "    \"\"\"Convert polars DataFrame to dict of numpy float64 arrays.\n",
    "    \n",
    "    Null/None values become NaN, which the IRT model detects as missing.\n",
    "    \"\"\"\n",
    "    data = {}\n",
    "    for col in dataframe.columns:\n",
    "        arr = dataframe[col].to_numpy().astype(np.float64)\n",
    "        data[col] = arr\n",
    "    # Re-index persons to 0..N-1\n",
    "    data['person'] = np.arange(len(dataframe), dtype=np.float64)\n",
    "    return data\n",
    "\n",
    "batch = make_data_dict(sub_df_missing)\n",
    "\n",
    "# Verify missingness in the batch\n",
    "n_bad_total = 0\n",
    "for k in item_keys:\n",
    "    col = batch[k]\n",
    "    n_bad = np.sum(np.isnan(col) | (col < 0) | (col >= 9))\n",
    "    n_bad_total += n_bad\n",
    "print(f\"Total bad/missing values in batch: {n_bad_total}\")\n",
    "\n",
    "# Minibatch setup\n",
    "BATCH_SIZE = 64\n",
    "steps_per_epoch = int(np.ceil(SUBSAMPLE_N / BATCH_SIZE))\n",
    "print(f\"Batch size: {BATCH_SIZE}, Steps per epoch: {steps_per_epoch}\")\n",
    "\n",
    "def data_factory():\n",
    "    # Simple shuffling and batching\n",
    "    indices = np.arange(SUBSAMPLE_N)\n",
    "    np.random.shuffle(indices)\n",
    "    for start_idx in range(0, SUBSAMPLE_N, BATCH_SIZE):\n",
    "        end_idx = min(start_idx + BATCH_SIZE, SUBSAMPLE_N)\n",
    "        idx_batch = indices[start_idx:end_idx]\n",
    "        # Slice the batch dict\n",
    "        yield {k: v[idx_batch] for k, v in batch.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fit-baseline",
   "metadata": {},
   "outputs": [],
   "source": "NUM_EPOCHS = 200\n\nmodel_baseline = FactorizedGRModel(\n    scale_indices=scale_indices,\n    kappa_scale=0.1,\n    item_keys=item_keys,\n    num_people=SUBSAMPLE_N,\n    response_cardinality=9,\n    dtype=jnp.float64,\n)\n\nlosses_baseline, params_baseline = model_baseline.fit(\n    data_factory,\n    batch_size=BATCH_SIZE,\n    dataset_size=SUBSAMPLE_N,\n    num_epochs=NUM_EPOCHS,\n    steps_per_epoch=steps_per_epoch,\n    learning_rate=2e-4,\n    patience=10,\n)\n\nprint(f\"Baseline final loss: {losses_baseline[-1]:.2f}\")"
  },
  {
   "cell_type": "markdown",
   "id": "imputed-header",
   "metadata": {},
   "source": [
    "## 5. Fit FactorizedGRModel WITH Stochastic Imputation\n",
    "\n",
    "Now fit the same model but with the MICEBayesianLOO imputation model.\n",
    "At each training step, missing values are stochastically filled from the\n",
    "imputation model's predictive distribution before computing the log-likelihood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fit-imputed",
   "metadata": {},
   "outputs": [],
   "source": "N_IMPUTATION_SAMPLES = 3\n\nmodel_imputed = FactorizedGRModel(\n    scale_indices=scale_indices,\n    kappa_scale=0.1,\n    item_keys=item_keys,\n    num_people=SUBSAMPLE_N,\n    response_cardinality=9,\n    dtype=jnp.float64,\n    imputation_model=mice_loo,\n)\n\n# Validate the imputation model first\nmodel_imputed.validate_imputation_model()\nprint(\"Imputation model validation passed.\")\n\nlosses_imputed, params_imputed = model_imputed.fit(\n    data_factory,\n    batch_size=BATCH_SIZE,\n    dataset_size=SUBSAMPLE_N,\n    num_epochs=NUM_EPOCHS,\n    steps_per_epoch=steps_per_epoch,\n    learning_rate=2e-4,\n    patience=10,\n    n_imputation_samples=N_IMPUTATION_SAMPLES,\n)\n\nprint(f\"Imputed final loss: {losses_imputed[-1]:.2f}\")"
  },
  {
   "cell_type": "markdown",
   "id": "compare-header",
   "metadata": {},
   "source": [
    "## 6. Compare Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compare-losses",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(losses_baseline, label='Baseline (zero-fill)', alpha=0.8)\n",
    "plt.plot(losses_imputed, label=f'Stochastic imputation (n={N_IMPUTATION_SAMPLES})', alpha=0.8)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss (neg ELBO)')\n",
    "plt.title('Training Loss: Baseline vs Stochastic Imputation')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compare-params",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare discrimination estimates\n",
    "def calibrate_manually(model, n_samples=32, seed=42):\n",
    "    # Generate the surrogate distribution from current params\n",
    "    surrogate = model.surrogate_distribution_generator(model.params)\n",
    "    \n",
    "    # Sample with a specific key\n",
    "    key = jax.random.PRNGKey(seed)\n",
    "    samples = surrogate.sample(n_samples, seed=key)\n",
    "    \n",
    "    # Compute expectations (means) for all parameters\n",
    "    expectations = {}\n",
    "    for k, v in samples.items():\n",
    "        # v has shape (n_samples, ...)\n",
    "        expectations[k] = jnp.mean(v, axis=0)\n",
    "        \n",
    "    model.calibrated_expectations = expectations\n",
    "\n",
    "calibrate_manually(model_baseline, n_samples=20, seed=101)\n",
    "calibrate_manually(model_imputed, n_samples=20, seed=102)\n",
    "\n",
    "fig, axes = plt.subplots(1, len(scale_indices), figsize=(14, 5))\n",
    "\n",
    "for j, (indices, ax) in enumerate(zip(scale_indices, axes)):\n",
    "    key = f'discriminations_{j}'\n",
    "    disc_base = np.array(model_baseline.calibrated_expectations[key]).flatten()\n",
    "    disc_imp = np.array(model_imputed.calibrated_expectations[key]).flatten()\n",
    "    labels = [item_keys[i] for i in indices]\n",
    "    \n",
    "    x = np.arange(len(labels))\n",
    "    width = 0.35\n",
    "    ax.barh(x - width/2, disc_base, width, label='Baseline', alpha=0.7)\n",
    "    ax.barh(x + width/2, disc_imp, width, label='Imputed', alpha=0.7)\n",
    "    ax.set_yticks(x)\n",
    "    ax.set_yticklabels(labels)\n",
    "    ax.set_title(f'Scale {j+1} Discriminations')\n",
    "    ax.set_xlabel('Discrimination')\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compare-abilities",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare ability distributions\n",
    "fig, axes = plt.subplots(1, len(scale_indices), figsize=(12, 4))\n",
    "\n",
    "for j, ax in enumerate(axes):\n",
    "    key = f'abilities_{j}'\n",
    "    ab_base = np.array(model_baseline.calibrated_expectations[key]).flatten()\n",
    "    ab_imp = np.array(model_imputed.calibrated_expectations[key]).flatten()\n",
    "    ax.hist(ab_base, bins=30, alpha=0.5, label='Baseline', edgecolor='black')\n",
    "    ax.hist(ab_imp, bins=30, alpha=0.5, label='Imputed', edgecolor='black')\n",
    "    ax.set_title(f'Scale {j+1} Abilities')\n",
    "    ax.set_xlabel('Ability')\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": "## Summary\n\nThis notebook demonstrated:\n\n1. **Data loading**: The `bayesianquilts.data.rwa` module downloads and preprocesses the RWA scale data without requiring `autoencirt`.\n2. **Artificial missingness**: We randomly masked 15% of responses to simulate MCAR missingness.\n3. **MICEBayesianLOO**: A Bayesian stacking imputation model was fitted to predict missing items from observed ones.\n4. **Baseline (zero-fill)**: The FactorizedGRModel handles missing responses by zeroing their log-likelihood contributions.\n5. **Stochastic imputation with Rao-Blackwellization**: By passing `imputation_model` to the FactorizedGRModel and `n_imputation_samples` to `fit()`, missing values are stochastically filled at each training step. The implementation uses proper Rao-Blackwellization: for each batch with missing data, M imputed copies are generated and the marginalized log-likelihood is computed as $\\log\\bigl[\\frac{1}{M}\\sum_m p(y_\\text{obs}, y_\\text{miss}^{(m)} \\mid \\theta)\\bigr] = \\mathrm{logsumexp}_m\\bigl[\\log p(y_\\text{obs}, y_\\text{miss}^{(m)} \\mid \\theta)\\bigr] - \\log M$. This averages likelihoods (not log-likelihoods), avoiding the Jensen's inequality lower bound that would result from treating each imputed copy as a separate mini-batch.\n6. **Comparison**: Both approaches produce parameter estimates; stochastic imputation uses more information from the data by leveraging cross-item correlations."
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}